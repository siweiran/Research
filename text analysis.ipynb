{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "017a32b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14e8b9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id product_first_release_date  product_name  \\\n",
      "0  1321171682                 2018-01-04           NaN   \n",
      "1  1376092414                 2018-04-26  !Arrow Match   \n",
      "2  1355027915                 2018-04-05   !Ball Chase   \n",
      "3  1370165429                 2018-04-16  !Dice In Cup   \n",
      "4  1447150646                 2019-01-05    !Fall Ball   \n",
      "\n",
      "               product_subtitle product_unified_category_name  \\\n",
      "0  Play Bridge with the best AI                         Games   \n",
      "1             Swipe to Match...                         Games   \n",
      "2          Just merge the balls                         Games   \n",
      "3       Find the hidden dice...                         Games   \n",
      "4    Show off your fall skills!                         Games   \n",
      "\n",
      "  publisher_name_cleaned  publisher_id  \\\n",
      "0        GREAT GAME PROD        202565   \n",
      "1           PRITI KALONI        391930   \n",
      "2         MULTIPLE CODES        339043   \n",
      "3           PRITI KALONI        391930   \n",
      "4                 MEMPIC        318172   \n",
      "\n",
      "                                 product_description  \n",
      "0  Totally Bridge is based on the best-selling co...  \n",
      "1  Please Note: This app is free, no IAP, cool ga...  \n",
      "2  Roll the ball to merge with other balls. Incre...  \n",
      "3  It is a game where a dice is placed inside a r...  \n",
      "4  Tap and fall to the next platforms and try not...  \n"
     ]
    }
   ],
   "source": [
    "# Load the Excel file into a DataFrame\n",
    "df = pd.read_excel('app_data.xlsx', engine='openpyxl')\n",
    "\n",
    "# Display the first few rows of the DataFrame to check if it's loaded correctly\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68ea1fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows dropped: 0\n"
     ]
    }
   ],
   "source": [
    "## Drop duplicates\n",
    "# Number of rows before removing duplicates\n",
    "initial_row_count = df.shape[0]\n",
    "\n",
    "# Remove duplicate rows based on 'product_id'\n",
    "df = df.drop_duplicates(subset='product_id')\n",
    "\n",
    "# Number of rows after removing duplicates\n",
    "after_duplicates_row_count = df.shape[0]\n",
    "\n",
    "# Calculate how many rows were dropped\n",
    "duplicates_dropped = initial_row_count - after_duplicates_row_count\n",
    "print(f'Number of duplicate rows dropped: {duplicates_dropped}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae4bbce5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language\n",
      "en       136400\n",
      "zh-cn     10487\n",
      "pt         3090\n",
      "ja         2433\n",
      "es         2108\n",
      "ko         2076\n",
      "da         1909\n",
      "vi         1208\n",
      "tr         1204\n",
      "ar         1101\n",
      "fr         1091\n",
      "de          925\n",
      "sv          886\n",
      "ru          708\n",
      "it          463\n",
      "id          414\n",
      "nl          272\n",
      "th          267\n",
      "pl          190\n",
      "no          158\n",
      "sq          150\n",
      "zh-tw       140\n",
      "ca          138\n",
      "cs          123\n",
      "ro           89\n",
      "hr           81\n",
      "he           65\n",
      "uk           64\n",
      "hu           55\n",
      "sk           44\n",
      "af           36\n",
      "el           33\n",
      "fa           30\n",
      "fi           28\n",
      "lt           26\n",
      "tl           22\n",
      "sl           18\n",
      "et           18\n",
      "cy           16\n",
      "hi           14\n",
      "lv            9\n",
      "so            9\n",
      "bg            9\n",
      "sw            6\n",
      "mk            3\n",
      "ur            2\n",
      "mr            1\n",
      "ne            1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Concatenate 'product_name', 'product_subtitle', and 'product_description'\n",
    "df['text'] = df['product_name'].fillna('') + ' ' + df['product_subtitle'].fillna('') + ' ' + df['product_description'].fillna('')\n",
    "\n",
    "# Detect the language of each text entry (if needed)\n",
    "df['language'] = df['text'].apply(lambda x: detect(x) if pd.notnull(x) else 'unknown')\n",
    "\n",
    "# Display the detected languages\n",
    "print(df['language'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e7dea2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/siweiran/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/siweiran/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/var/folders/t6/61zchkjx5g9b4pgj5_m3fcnr0000gn/T/ipykernel_20002/4221747793.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_english['cleaned_text'] = df_english['text'].apply(clean_text)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the stemmer and stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to clean and stem text\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # Remove punctuation and special characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [stemmer.stem(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Focus on English texts\n",
    "df_english = df[df['language'] == 'en']\n",
    "\n",
    "# Apply text cleaning\n",
    "df_english['cleaned_text'] = df_english['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b5cabbc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/61zchkjx5g9b4pgj5_m3fcnr0000gn/T/ipykernel_20002/1525826957.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_english['product_first_release_date'] = pd.to_datetime(df_english['product_first_release_date'], errors='coerce')\n",
      "/var/folders/t6/61zchkjx5g9b4pgj5_m3fcnr0000gn/T/ipykernel_20002/1525826957.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_english['year_month'] = df_english['product_first_release_date'].dt.to_period('M')\n"
     ]
    }
   ],
   "source": [
    "# Convert 'product_first_release_date' to datetime format\n",
    "df_english['product_first_release_date'] = pd.to_datetime(df_english['product_first_release_date'], errors='coerce')\n",
    "\n",
    "# Extract year and month for grouping\n",
    "df_english['year_month'] = df_english['product_first_release_date'].dt.to_period('M')\n",
    "\n",
    "# Sort data by release date\n",
    "df_english = df_english.sort_values(by='product_first_release_date')\n",
    "\n",
    "# Split the dataset by category\n",
    "games_df = df_english[df_english['product_unified_category_name'] == 'Games']\n",
    "education_df = df_english[df_english['product_unified_category_name'] == 'Education']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02257ca",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb67046f",
   "metadata": {},
   "source": [
    "## 3 months window within each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5708766d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define a function to compute similarity for a given category DataFrame\n",
    "def compute_similarity_for_3_month(category_df):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    similarity_results = []\n",
    "\n",
    "    for current_month in category_df['year_month'].unique():\n",
    "        current_month_apps = category_df[category_df['year_month'] == current_month]\n",
    "        \n",
    "        # Calculate the start of the 3-month window\n",
    "        three_months_before = current_month - 3  # Subtract 3 months directly\n",
    "        \n",
    "        # Select previous apps within the 3-month window\n",
    "        previous_apps = category_df[(category_df['year_month'] < current_month) &\n",
    "                                    (category_df['year_month'] >= three_months_before)]\n",
    "        \n",
    "        # If there are no apps within the 3-month window, select all previous apps\n",
    "        if previous_apps.empty:\n",
    "            previous_apps = category_df[category_df['product_first_release_date'] < current_month.start_time]\n",
    "\n",
    "        # Handle case when there are no previous apps at all\n",
    "        if previous_apps.empty:\n",
    "            for app_id in current_month_apps['product_id']:\n",
    "                similarity_results.append({\n",
    "                    'product_id': app_id,\n",
    "                    'max_similarity': np.nan,\n",
    "                    'avg_similarity': np.nan,\n",
    "                    'top_5_similar_apps': []\n",
    "                })\n",
    "            continue\n",
    "\n",
    "        vectorizer.fit(previous_apps['cleaned_text'])\n",
    "        previous_tfidf = vectorizer.transform(previous_apps['cleaned_text'])\n",
    "        current_tfidf = vectorizer.transform(current_month_apps['cleaned_text'])\n",
    "        \n",
    "        cosine_sim_matrix = cosine_similarity(current_tfidf, previous_tfidf)\n",
    "        \n",
    "        for i, app_id in enumerate(current_month_apps['product_id']):\n",
    "            sim_scores = cosine_sim_matrix[i]\n",
    "            top_indices = np.argsort(sim_scores)[-5:][::-1]\n",
    "            top_similarities = sim_scores[top_indices]\n",
    "            top_apps = previous_apps.iloc[top_indices]['product_id'].tolist()\n",
    "            \n",
    "            similarity_results.append({\n",
    "                'product_id': app_id,\n",
    "                'max_similarity': top_similarities[0] if top_similarities.size > 0 else np.nan,\n",
    "                'avg_similarity': np.mean(top_similarities) if top_similarities.size > 0 else np.nan,\n",
    "                'top_5_similar_apps': top_apps\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(similarity_results)\n",
    "\n",
    "# Compute similarity separately for Games and Education\n",
    "games_similarity_results = compute_similarity_for_3_month(games_df)\n",
    "education_similarity_results = compute_similarity_for_3_month(education_df)\n",
    "\n",
    "# Save the Games similarity results to a CSV file\n",
    "games_similarity_results.to_csv('games_similarity_3_months_results.csv', index=False)\n",
    "\n",
    "# Save the Education similarity results to a CSV file\n",
    "education_similarity_results.to_csv('education_similarity_3_months_results.csv', index=False)\n",
    "\n",
    "print(\"Files have been saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c8f26",
   "metadata": {},
   "source": [
    "## 6 months window within each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ddb377c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define a function to compute similarity for a given category DataFrame\n",
    "def compute_similarity_for_6_month(category_df):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    similarity_results = []\n",
    "\n",
    "    for current_month in category_df['year_month'].unique():\n",
    "        current_month_apps = category_df[category_df['year_month'] == current_month]\n",
    "        \n",
    "        # Calculate the start of the 6-month window\n",
    "        six_months_before = current_month - 6  # Subtract 6 months directly\n",
    "        \n",
    "        # Select previous apps within the 6-month window\n",
    "        previous_apps = category_df[(category_df['year_month'] < current_month) &\n",
    "                                    (category_df['year_month'] >= six_months_before)]\n",
    "        \n",
    "        # If there are no apps within the 6-month window, select all previous apps\n",
    "        if previous_apps.empty:\n",
    "            previous_apps = category_df[category_df['product_first_release_date'] < current_month.start_time]\n",
    "\n",
    "        # Handle case when there are no previous apps at all\n",
    "        if previous_apps.empty:\n",
    "            for app_id in current_month_apps['product_id']:\n",
    "                similarity_results.append({\n",
    "                    'product_id': app_id,\n",
    "                    'max_similarity': np.nan,\n",
    "                    'avg_similarity': np.nan,\n",
    "                    'top_5_similar_apps': []\n",
    "                })\n",
    "            continue\n",
    "\n",
    "        vectorizer.fit(previous_apps['cleaned_text'])\n",
    "        previous_tfidf = vectorizer.transform(previous_apps['cleaned_text'])\n",
    "        current_tfidf = vectorizer.transform(current_month_apps['cleaned_text'])\n",
    "        \n",
    "        cosine_sim_matrix = cosine_similarity(current_tfidf, previous_tfidf)\n",
    "        \n",
    "        for i, app_id in enumerate(current_month_apps['product_id']):\n",
    "            sim_scores = cosine_sim_matrix[i]\n",
    "            top_indices = np.argsort(sim_scores)[-5:][::-1]\n",
    "            top_similarities = sim_scores[top_indices]\n",
    "            top_apps = previous_apps.iloc[top_indices]['product_id'].tolist()\n",
    "            \n",
    "            similarity_results.append({\n",
    "                'product_id': app_id,\n",
    "                'max_similarity': top_similarities[0] if top_similarities.size > 0 else np.nan,\n",
    "                'avg_similarity': np.mean(top_similarities) if top_similarities.size > 0 else np.nan,\n",
    "                'top_5_similar_apps': top_apps\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(similarity_results)\n",
    "\n",
    "# Compute similarity separately for Games and Education\n",
    "games_similarity_results = compute_similarity_for_6_month(games_df)\n",
    "education_similarity_results = compute_similarity_for_6_month(education_df)\n",
    "\n",
    "# Save the Games similarity results to a CSV file\n",
    "games_similarity_results.to_csv('games_similarity_6_months_results.csv', index=False)\n",
    "\n",
    "# Save the Education similarity results to a CSV file\n",
    "education_similarity_results.to_csv('education_similarity_6_months_results.csv', index=False)\n",
    "\n",
    "print(\"Files have been saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85a629f",
   "metadata": {},
   "source": [
    "## 3 months window of all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7e6bfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Compute similarity separately for Games and Education\n",
    "all_similarity_results = compute_similarity_for_3_month(df_english)\n",
    "\n",
    "# Save the similarity results to a CSV file\n",
    "all_similarity_results.to_csv('all_similarity_3_months_results.csv', index=False)\n",
    "\n",
    "print(\"Files have been saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08d3a9a",
   "metadata": {},
   "source": [
    "## 6 months window of all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56f6660a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Compute similarity separately for Games and Education\n",
    "all_similarity_results = compute_similarity_for_6_month(df_english)\n",
    "\n",
    "# Save the similarity results to a CSV file\n",
    "all_similarity_results.to_csv('all_similarity_6_months_results.csv', index=False)\n",
    "\n",
    "print(\"Files have been saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4345f1e",
   "metadata": {},
   "source": [
    "# Classify the publisher into \"Big\" or \"Small\" and then use TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "802ea06f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        publisher_id  company_size\n",
      "1979          538488             0\n",
      "48937          87226             0\n",
      "11508         322778             0\n",
      "410            68928             0\n",
      "88416          98904             0\n",
      "...              ...           ...\n",
      "2180            5507             1\n",
      "118532        186609             0\n",
      "57864         227315             0\n",
      "123673        519490             0\n",
      "110994        470135             0\n",
      "\n",
      "[67379 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Count the number of apps per publisher\n",
    "app_counts = df_english.groupby('publisher_id').size()\n",
    "\n",
    "# Classify companies as 'big' or 'small' based on the count of published apps\n",
    "# If the count of apps is greater than 4, it's a big company (1), otherwise small (0)\n",
    "df_english['company_size'] = df_english['publisher_id'].apply(lambda x: 1 if app_counts[x] > 4 else 0)\n",
    "\n",
    "# Inspect the result\n",
    "print(df_english[['publisher_id', 'company_size']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf222a2a",
   "metadata": {},
   "source": [
    "## 3-months window of different categories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "916535f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Function to compute similarity for a given category DataFrame within a 3-month window\n",
    "def compute_similarity_for_3_month(category_df):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    similarity_results = []\n",
    "\n",
    "    # Loop over each month in the data\n",
    "    for current_month in category_df['year_month'].unique():\n",
    "        current_month_apps = category_df[category_df['year_month'] == current_month]\n",
    "        \n",
    "        # Calculate the start of the 3-month window\n",
    "        three_months_before = current_month - 3\n",
    "        \n",
    "        # Select previous apps within the 3-month window from big companies only\n",
    "        previous_apps = category_df[(category_df['year_month'] < current_month) &\n",
    "                                    (category_df['year_month'] >= three_months_before) &\n",
    "                                    (category_df['company_size'] == 1)]  # Only big companies\n",
    "\n",
    "        # If no apps in the 3-month window, select all previous apps from big companies\n",
    "        if previous_apps.empty:\n",
    "            previous_apps = category_df[(category_df['product_first_release_date'] < current_month.start_time) &\n",
    "                                        (category_df['company_size'] == 1)]  # Only big companies\n",
    "\n",
    "        # Handle case when there are no previous apps at all\n",
    "        if previous_apps.empty:\n",
    "            for app_id in current_month_apps['product_id']:\n",
    "                similarity_results.append({\n",
    "                    'product_id': app_id,\n",
    "                    'max_similarity': np.nan,\n",
    "                    'avg_similarity': np.nan,\n",
    "                    'top_5_similar_apps': []\n",
    "                })\n",
    "            continue\n",
    "\n",
    "        # Apply TF-IDF to the apps in the previous and current month\n",
    "        vectorizer.fit(previous_apps['cleaned_text'])\n",
    "        previous_tfidf = vectorizer.transform(previous_apps['cleaned_text'])\n",
    "        current_tfidf = vectorizer.transform(current_month_apps['cleaned_text'])\n",
    "        \n",
    "        # Compute cosine similarity between current and previous apps\n",
    "        cosine_sim_matrix = cosine_similarity(current_tfidf, previous_tfidf)\n",
    "\n",
    "        # Collect results for each app in the current month\n",
    "        for i, app_id in enumerate(current_month_apps['product_id']):\n",
    "            sim_scores = cosine_sim_matrix[i]\n",
    "            top_indices = np.argsort(sim_scores)[-5:][::-1]\n",
    "            top_similarities = sim_scores[top_indices]\n",
    "            top_apps = previous_apps.iloc[top_indices]['product_id'].tolist()\n",
    "\n",
    "            similarity_results.append({\n",
    "                'product_id': app_id,\n",
    "                'max_similarity': top_similarities[0] if top_similarities.size > 0 else np.nan,\n",
    "                'avg_similarity': np.mean(top_similarities) if top_similarities.size > 0 else np.nan,\n",
    "                'top_5_similar_apps': top_apps\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(similarity_results)\n",
    "\n",
    "# Split the dataset by category\n",
    "games_df = df_english[df_english['product_unified_category_name'] == 'Games']\n",
    "education_df = df_english[df_english['product_unified_category_name'] == 'Education']\n",
    "\n",
    "\n",
    "# Compute similarity within a 3-month window for Games and Education, only comparing to big companies\n",
    "games_similarity_results = compute_similarity_for_3_month(games_df)\n",
    "education_similarity_results = compute_similarity_for_3_month(education_df)\n",
    "\n",
    "# Save the results to CSV files\n",
    "games_similarity_results.to_csv('games_similarity_3_months_big_companies.csv', index=False)\n",
    "education_similarity_results.to_csv('education_similarity_3_months_big_companies.csv', index=False)\n",
    "\n",
    "print(\"Files have been saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc27d350",
   "metadata": {},
   "source": [
    "## All time similarities in different categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "147a2928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Function to compute similarity for a given category DataFrame with all previous apps from big companies\n",
    "def compute_similarity_with_previous_big_companies(category_df):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    similarity_results = []\n",
    "\n",
    "    # Loop over each month in the data\n",
    "    for current_month in category_df['year_month'].unique():\n",
    "        current_month_apps = category_df[category_df['year_month'] == current_month]\n",
    "        \n",
    "        # Select all previous apps from big companies before the current month\n",
    "        previous_apps = category_df[(category_df['year_month'] < current_month) &\n",
    "                                    (category_df['company_size'] == 1)]  # Only big companies\n",
    "\n",
    "        # Handle case when there are no previous apps at all\n",
    "        if previous_apps.empty:\n",
    "            for app_id in current_month_apps['product_id']:\n",
    "                similarity_results.append({\n",
    "                    'product_id': app_id,\n",
    "                    'max_similarity': np.nan,\n",
    "                    'avg_similarity': np.nan,\n",
    "                    'top_5_similar_apps': []\n",
    "                })\n",
    "            continue\n",
    "\n",
    "        # Apply TF-IDF to the apps in the previous and current month\n",
    "        vectorizer.fit(previous_apps['cleaned_text'])\n",
    "        previous_tfidf = vectorizer.transform(previous_apps['cleaned_text'])\n",
    "        current_tfidf = vectorizer.transform(current_month_apps['cleaned_text'])\n",
    "        \n",
    "        # Compute cosine similarity between current and previous apps\n",
    "        cosine_sim_matrix = cosine_similarity(current_tfidf, previous_tfidf)\n",
    "\n",
    "        # Collect results for each app in the current month\n",
    "        for i, app_id in enumerate(current_month_apps['product_id']):\n",
    "            sim_scores = cosine_sim_matrix[i]\n",
    "            top_indices = np.argsort(sim_scores)[-5:][::-1]\n",
    "            top_similarities = sim_scores[top_indices]\n",
    "            top_apps = previous_apps.iloc[top_indices]['product_id'].tolist()\n",
    "\n",
    "            similarity_results.append({\n",
    "                'product_id': app_id,\n",
    "                'max_similarity': top_similarities[0] if top_similarities.size > 0 else np.nan,\n",
    "                'avg_similarity': np.mean(top_similarities) if top_similarities.size > 0 else np.nan,\n",
    "                'top_5_similar_apps': top_apps\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(similarity_results)\n",
    "\n",
    "# Compute similarity for Games and Education, comparing with all previous apps from big companies\n",
    "games_similarity_results = compute_similarity_with_previous_big_companies(games_df)\n",
    "education_similarity_results = compute_similarity_with_previous_big_companies(education_df)\n",
    "\n",
    "# Save the results to CSV files\n",
    "games_similarity_results.to_csv('games_similarity_all_previous_big_companies.csv', index=False)\n",
    "education_similarity_results.to_csv('education_similarity_all_previous_big_companies.csv', index=False)\n",
    "\n",
    "print(\"Files have been saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b795e8",
   "metadata": {},
   "source": [
    "## 3-months window under all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f492c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the entire dataset (without separating by category)\n",
    "similarity_results = compute_similarity_for_3_month(df_english)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "similarity_results.to_csv('similarity_3_months_big_companies.csv', index=False)\n",
    "\n",
    "print(\"File has been saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9302e511",
   "metadata": {},
   "source": [
    "## All time similarities under all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbd7a819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the entire dataset (without separating by category)\n",
    "similarity_results = compute_similarity_with_previous_big_companies(df_english)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "similarity_results.to_csv('similarity_all_previous_big_companies.csv', index=False)\n",
    "\n",
    "print(\"File has been saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3543ccea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
